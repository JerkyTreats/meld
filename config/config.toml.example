# Merkle Configuration File
#
# This is an example configuration file for the Merkle filesystem state management system.
# Copy this file to `config/config.toml` or `.merkle/config.toml` and customize it for your needs.
#
# Configuration is loaded in the following order (highest to lowest precedence):
# 1. Environment variables (MERKLE_* prefix)
# 2. Environment-specific files (config/production.toml, config/development.toml)
# 3. Base configuration file (config/config.toml or .merkle/config.toml)
# 4. Default values
#
# NOTE: Agents and providers can also be stored in XDG directories:
#   - Agents: $XDG_CONFIG_HOME/merkle/agents/*.toml
#   - Providers: $XDG_CONFIG_HOME/merkle/providers/*.toml
# XDG configurations override config.toml configurations.

[system]
# Default workspace root (if not specified)
default_workspace_root = "."

# ============================================================================
# Logging
# ============================================================================
# Logging is enabled by default and writes to a file under the platform state
# directory. Override with --log-file, MERKLE_LOG_FILE, or the options below.
# output: file, stdout, stderr, file+stderr, or both. file path is optional;
# when unset, the default path under the state directory is used.

[logging]
enabled = true
level = "info"
format = "text"
output = "file"
# file = null
color = true

[system.storage]
# Path to node record store
# Default: ".merkle/store" (resolved to $XDG_DATA_HOME/merkle/<workspace_path>/store)
# If set to a custom path, it will be resolved relative to workspace root
store_path = ".merkle/store"

# Path to frame storage
# Default: ".merkle/frames" (resolved to $XDG_DATA_HOME/merkle/<workspace_path>/frames)
# If set to a custom path, it will be resolved relative to workspace root
frames_path = ".merkle/frames"

# ============================================================================
# Model Provider Configurations
# ============================================================================
# Define model providers that can be used by agents at runtime. Each provider
# has a unique name and configuration. API keys can be set here or via
# environment variables.
#
# NOTE: Providers can also be stored in XDG directories:
#   $XDG_CONFIG_HOME/merkle/providers/<provider_name>.toml
#
# Providers in XDG directories take precedence over config.toml providers.
# Use 'merkle provider' commands to manage providers in XDG directories.
#
# IMPORTANT: The provider name is the part after "providers." in the table name.
# For example, [providers.openai-gpt4] creates a provider with name "openai-gpt4".
# Providers are selected at runtime when generating frames, not in agent config.

[providers.openai-gpt4]
provider_type = "openai"
model = "gpt-4"
# API key can be set here or via OPENAI_API_KEY environment variable
# api_key = "sk-..."
endpoint = null
[providers.openai-gpt4.default_options]
temperature = 0.7
max_tokens = 2000
top_p = 0.9

[providers.openai-gpt35]
provider_type = "openai"
model = "gpt-3.5-turbo"
# api_key loaded from OPENAI_API_KEY environment variable
endpoint = null
[providers.openai-gpt35.default_options]
temperature = 0.8
max_tokens = 1500

[providers.anthropic-claude]
provider_type = "anthropic"
model = "claude-3-opus-20240229"
# API key can be set here or via ANTHROPIC_API_KEY environment variable
# api_key = "sk-ant-..."
[providers.anthropic-claude.default_options]
temperature = 0.8
max_tokens = 2000

[providers.local-ollama]
provider_type = "ollama"
model = "llama2"
# Default endpoint is http://localhost:11434
endpoint = "http://localhost:11434"
[providers.local-ollama.default_options]
temperature = 0.8
max_tokens = 1500

[providers.local-custom]
provider_type = "local"
model = "custom-model"
# Full endpoint URL for OpenAI-compatible API
endpoint = "http://localhost:8080/v1"
# Optional API key if your local server requires authentication
# api_key = "local-key"
[providers.local-custom.default_options]
temperature = 0.7
max_tokens = 2000

# ============================================================================
# Watch Mode Configuration
# ============================================================================
# Configuration for watch mode daemon and automatic frame generation

[watch]
# Enable automatic LLM-based frame generation
auto_generate_frames = true

# Frame generation queue configuration
[watch.generation]
# Maximum concurrent generations per agent
max_concurrent_per_agent = 3

# Batch size for processing requests
batch_size = 50

# Maximum retry attempts per request
max_retry_attempts = 3

# Delay between retries (milliseconds)
retry_delay_ms = 1000

# Rate limit: minimum delay between requests per agent (milliseconds)
# Set to null to disable rate limiting
rate_limit_ms = 100

# Maximum queue size (prevents memory exhaustion)
max_queue_size = 10000

# Number of worker tasks per agent
workers_per_agent = 2
